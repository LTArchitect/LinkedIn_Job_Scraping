{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LinkedIn Job Scraping\n",
        "\n",
        "### Version 1.0\n",
        "#### Created by Long\n",
        "\n",
        "### Overview\n",
        "This notebook is designed to scrape tech-related job postings from LinkedIn. The goal is to extract key information such as job titles, company names, locations, job links, posting dates, and Easy Apply availability. The data is then saved into a CSV file for further analysis.\n",
        "\n",
        "### How it Works\n",
        "- **Data Source**: The HTML content of LinkedIn job search result pages is fetched using the `requests` library.\n",
        "- **Web Scraping**: `BeautifulSoup` is used to parse the HTML and extract job details like titles, companies, and locations.\n",
        "- **Data Output**: The extracted data is stored in a CSV file, making it easy to analyze or manipulate for further use.\n",
        "- **Customization**: Filters can be applied manually on LinkedIn before fetching the data to focus on specific job criteria like location, job type, or posting date.\n",
        "\n",
        "### Future Enhancements\n",
        "In future iterations, this notebook can be expanded to:\n",
        "- Automatically generate the LinkedIn job search URL based on user keyword input.\n",
        "- Extract more detailed data from the job postings, such as experience level, required skills, and qualifications.\n",
        "\n"
      ],
      "metadata": {
        "id": "dfQKo-3HhYjh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpIN4HcJhJrt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take User input and generate the LinkedIn URL\n",
        "\n",
        "def generate_linkedin_url():\n",
        "    # User input\n",
        "    keywords = input(\"Enter job keywords (e.g., 'Cyber Security'): \").strip()\n",
        "    location = input(\"Enter location (Calgary or Edmonton): \").strip().capitalize()\n",
        "    distance = input(\"Enter distance in miles (e.g., 25): \").strip()\n",
        "\n",
        "    # Time posted options\n",
        "    print(\"Select time period for job posting:\")\n",
        "    print(\"1. Last 24 hours\")\n",
        "    print(\"2. Last week\")\n",
        "    print(\"3. Last month\")\n",
        "    time_choice = input(\"Enter 1, 2, or 3: \").strip()\n",
        "\n",
        "    # Map time choice to f_TPR values\n",
        "    time_mapping = {\n",
        "        '1': 'r86400',   # Last 24 hours\n",
        "        '2': 'r604800',  # Last week\n",
        "        '3': 'r2592000'  # Last month\n",
        "    }\n",
        "\n",
        "    # GeoId based on location\n",
        "    location_mapping = {\n",
        "        'Calgary': '102199904',\n",
        "        'Edmonton': '106535873'\n",
        "    }\n",
        "\n",
        "    # Validate user input\n",
        "    if location not in location_mapping:\n",
        "        print(f\"Invalid location: {location}\")\n",
        "        return\n",
        "\n",
        "    if time_choice not in time_mapping:\n",
        "        print(f\"Invalid time period: {time_choice}\")\n",
        "        return\n",
        "\n",
        "    # Generate URL\n",
        "    geo_id = location_mapping[location]\n",
        "    f_tpr = time_mapping[time_choice]\n",
        "\n",
        "    # Save the URL in the PAGE_URL variable\n",
        "    PAGE_URL = (f\"https://www.linkedin.com/jobs/search?keywords={keywords.replace(' ', '%20')}\"\n",
        "                f\"&location={location}&geoId={geo_id}&distance={distance}&f_TPR={f_tpr}&position=1&pageNum=0\")\n",
        "\n",
        "    return PAGE_URL\n",
        "\n",
        "\n",
        "# Call the function\n",
        "PAGE_URL = generate_linkedin_url()\n",
        "\n",
        "# Print the URL for verification (optional)\n",
        "print(f\"LinkedIn URL generated and saved: {PAGE_URL}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFWktkpotxgh",
        "outputId": "450604d2-4df6-4153-811a-e2ac8ac9d224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter job keywords (e.g., 'Cyber Security'): Data Analyst\n",
            "Enter location (Calgary or Edmonton): Edmonton\n",
            "Enter distance in miles (e.g., 25): 25\n",
            "Select time period for job posting:\n",
            "1. Last 24 hours\n",
            "2. Last week\n",
            "3. Last month\n",
            "Enter 1, 2, or 3: 2\n",
            "LinkedIn URL generated and saved: https://www.linkedin.com/jobs/search?keywords=Data%20Analyst&location=Edmonton&geoId=106535873&distance=25&f_TPR=r604800&position=1&pageNum=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually filter on LinkedIn then add the link\n",
        "# PAGE_URL = 'https://www.linkedin.com/jobs/search/?currentJobId=4030602244&f_PP=102199904%2C106535873&f_TPR=r2592000&geoId=103564821&keywords=cybersecurity&origin=JOB_SEARCH_PAGE_JOB_FILTER&refresh=true&sortBy=R'"
      ],
      "metadata": {
        "id": "RDzv63SYCD1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the html of the page\n",
        "def get_html_of(url):\n",
        "    resp = requests.get(url)\n",
        "\n",
        "    if resp.status_code != 200:\n",
        "        print(f'HTTP status code of {resp.status_code} returned, but 200 was expected.')\n",
        "        print(\"Please delete the 'linkedin_search_results.html' file and try again after waiting for some time.\")\n",
        "        print('Exiting...')\n",
        "        exit(1)\n",
        "\n",
        "    return resp.content.decode()\n",
        "\n",
        "html_content = get_html_of(PAGE_URL)\n",
        "with open(\"linkedin_search_results.html\", \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(html_content)\n",
        "\n",
        "print(\"HTML content saved to 'linkedin_search_results.html'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtgRCqrihWz4",
        "outputId": "2be236a2-4752-4c47-d303-4db9588ca71e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML content saved to 'linkedin_search_results.html'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract job details\n",
        "def extract_jobs(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    jobs = []\n",
        "\n",
        "    for job_card in soup.find_all('div', class_='base-search-card__info'):\n",
        "        title = job_card.find('h3', class_='base-search-card__title').text.strip()\n",
        "        company = job_card.find('h4', class_='base-search-card__subtitle').text.strip()\n",
        "        location = job_card.find('span', class_='job-search-card__location').text.strip()\n",
        "\n",
        "        # Extract job link\n",
        "        job_link = job_card.find('a')['href']\n",
        "\n",
        "        # Extract date posted\n",
        "        date_posted = job_card.find('time', class_='job-search-card__listdate').text.strip() if job_card.find('time', class_='job-search-card__listdate') else \"Not listed\"\n",
        "\n",
        "        # Check if the job is an \"Easy Apply\"\n",
        "        easy_apply = job_card.find('span', class_='apply-button--easy').text.strip() if job_card.find('span', class_='apply-button--easy') else \"No\"\n",
        "\n",
        "        # Add extracted data to list\n",
        "        jobs.append({\n",
        "            'Job Title': title,\n",
        "            'Company': company,\n",
        "            'Location': location,\n",
        "            'Job Link': job_link,\n",
        "            'Date Posted': date_posted,\n",
        "            'Easy Apply': easy_apply\n",
        "        })\n",
        "\n",
        "    return jobs\n",
        "\n",
        "# Get HTML content\n",
        "html_content = get_html_of(PAGE_URL)"
      ],
      "metadata": {
        "id": "5jQ0lY0XksIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract job details\n",
        "job_listings = extract_jobs(html_content)\n",
        "\n",
        "# Convert the job listings to a pandas DataFrame\n",
        "df = pd.DataFrame(job_listings)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('linkedin_job_listings.csv', index=False)\n",
        "\n",
        "print(\"Job listings have been saved to 'linkedin_job_listings.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot5BtO7BlTOU",
        "outputId": "670b6e49-e6ec-473c-f927-6dbadc897c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job listings have been saved to 'linkedin_job_listings.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzgqAGh1AkdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}